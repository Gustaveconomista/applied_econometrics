# Meu Rejection rate (wild cluster bootstrap-SE, B=399): 0.0180; Desvio-padrão da rejection rate: 0.0042 
# Meu Rejection rate (wild cluster bootstrap-SE, B=399) :0.012; Desvio-padrão da rejection rate: 0.003

# ================================================
# Wild Cluster Bootstrap-SE (Cameron-Gelbach-Miller, 2008)
# ================================================
import numpy as np
import pandas as pd
import statsmodels.api as sm
from numpy.random import default_rng
from scipy.stats import norm, t as tdist

# -----------------------------
# Parâmetros
# -----------------------------
G = 5       # número de clusters
NG = 30     # observações por cluster
R = 1000    # replicações Monte Carlo
B = 399     # reamostragens bootstrap (wild cluster bootstrap-SE)
beta_0 = 0
beta_1 = 1
alpha = 0.05

rng = default_rng(42)

# -----------------------------
# DGP
# -----------------------------
def generate_data(G, NG, beta_0=0, beta_1=1, rng=None):
    if rng is None:
        rng = default_rng()
    zg = rng.normal(size=G)        # componente comum em x
    eps_g = rng.normal(size=G)     # componente comum no erro

    data_list = []
    for g in range(G):
        zig   = rng.normal(size=NG)    # idiossincrático x
        eps_i = rng.normal(size=NG)    # idiossincrático erro

        xig = zg[g] + zig
        uig = eps_g[g] + eps_i
        yig = beta_0 + beta_1 * xig + uig

        data_list.append(pd.DataFrame({
            "y": yig, "x": xig, "cluster": g + 1
        }))
    return pd.concat(data_list, ignore_index=True)

# -----------------------------
# OLS (para coletar beta1)
# -----------------------------
def fit_ols_beta1(df):
    X = sm.add_constant(df["x"].to_numpy())
    y = df["y"].to_numpy()
    ols = sm.OLS(y, X).fit()
    return float(ols.params[1])

# -----------------------------
# Pesos wild por cluster
#   scheme='rademacher' (padrão) ou 'mammen'
# -----------------------------
def draw_wild_weights(clusters, rng, scheme="rademacher"):
    uniq = np.unique(clusters)
    w_by_cluster = {}
    if scheme == "rademacher":
        for g in uniq:
            w_by_cluster[g] = rng.choice([-1.0, 1.0])  # 0.5/0.5
    elif scheme == "mammen":
        phi = np.sqrt(5.0)
        a, b = (1.0 - phi) / 2.0, (1.0 + phi) / 2.0
        p_a = 0.5 + 1.0 / (2.0 * phi)  # ~= 0.7236
        for g in uniq:
            w_by_cluster[g] = a if (rng.random() < p_a) else b
    else:
        raise ValueError("scheme deve ser 'rademacher' ou 'mammen'")
    # mapeia p/ cada observação
    return np.array([w_by_cluster[g] for g in clusters])

# -----------------------------
# Wild Cluster Bootstrap-SE (CGM 2008)
# Retorna: se_boot, wald, p_value
# -----------------------------
def wild_cluster_bootstrap_se(df, beta_true, B=399, rng=None,
                              weight_scheme="rademacher",
                              crit_dist="normal"):
    """
    crit_dist: 'normal' (padrão) ou 't' (usa df=G-1)
    """
    if rng is None:
        rng = default_rng()
    # 1) Estimativa original irrestrita
    beta1_hat = fit_ols_beta1(df)

    # 2) Ajuste restrito (impõe H0): regressa (y - beta_true*x) em constante
    y = df["y"].to_numpy()
    x = df["x"].to_numpy()
    clusters = df["cluster"].to_numpy()
    G = int(np.unique(clusters).size)

    y_restr = y - beta_true * x
    Xc = np.ones((len(df), 1))
    ols_c = sm.OLS(y_restr, Xc).fit()
    c_hat = float(ols_c.params[0])

    y_hat0 = beta_true * x + c_hat
    e0 = y - y_hat0  # resíduos sob H0

    # 3) Réplicas bootstrap: gera y* = y_hat0 + w_g * e0
    betas_star = np.empty(B)
    X_full = sm.add_constant(x)
    for b in range(B):
        w = draw_wild_weights(clusters, rng, scheme=weight_scheme)
        y_star = y_hat0 + w * e0
        ols_star = sm.OLS(y_star, X_full).fit()
        betas_star[b] = float(ols_star.params[1])

    # 4) SE bootstrap = desvio-padrão dos betas* (Bessel, ddof=1)
    se_boot = float(np.std(betas_star, ddof=1))
    # prevenção contra degenerescência numérica
    if not np.isfinite(se_boot) or se_boot <= 1e-12:
        # se não há variabilidade, o teste não rejeita
        return se_boot, np.nan, 1.0

    # 5) Estatística Wald com SE bootstrap
    wald = (beta1_hat - beta_true) / se_boot

    # 6) p-valor bicaudal
    if crit_dist.lower() == "normal":
        p_value = 2.0 * (1.0 - norm.cdf(abs(wald)))
    elif crit_dist.lower() == "t":
        df = max(G - 1, 1)
        p_value = 2.0 * (1.0 - tdist.cdf(abs(wald), df=df))
    else:
        raise ValueError("crit_dist deve ser 'normal' ou 't'.")

    return se_boot, float(wald), float(p_value)

# -----------------------------
# Monte Carlo p/ tamanho do teste
# -----------------------------
def run_monte_carlo_wild_cluster_se(R, G, NG, beta_true=1.0, B=399,
                                    alpha=0.05, rng=None,
                                    weight_scheme="rademacher",
                                    crit_dist="normal"):
    if rng is None:
        rng = default_rng()
    rejects = []
    for r in range(R):
        df = generate_data(G, NG, beta_0=0, beta_1=beta_true, rng=rng)
        se_b, wald, pval = wild_cluster_bootstrap_se(
            df, beta_true=beta_true, B=B, rng=rng,
            weight_scheme=weight_scheme, crit_dist=crit_dist
        )
        rejects.append(pval < alpha)

    rejection_rate = float(np.mean(rejects))
    sd_rejection = float(np.sqrt(rejection_rate * (1 - rejection_rate) / R))
    return rejection_rate, sd_rejection

# -----------------------------
# Executar (ex.: crítico Normal + Rademacher)
# -----------------------------
if __name__ == "__main__":
    rej, sd_rej = run_monte_carlo_wild_cluster_se(
        R=R, G=G, NG=NG, beta_true=beta_1, B=B, alpha=alpha,
        rng=rng, weight_scheme="rademacher", crit_dist="normal"
    )
    print(f"Rejection rate (wild cluster bootstrap-SE, B={B}): {rej:.4f}")
    print(f"Desvio-padrão da rejection rate: {sd_rej:.4f}")

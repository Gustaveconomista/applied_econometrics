# ================================================
# Pairs Cluster Bootstrap-BCA (PARALELIZADO)
# ================================================
import numpy as np
import pandas as pd
import statsmodels.api as sm
from numpy.random import default_rng
from scipy.stats import norm
from joblib import Parallel, delayed

# -----------------------------
# Parâmetros
# -----------------------------
G = 5       # número de clusters
NG = 30     # observações por cluster
R = 1000    # replicações Monte Carlo
B = 399     # reamostragens bootstrap (pairs cluster)
beta_0 = 0
beta_1 = 1
alpha = 0.05

MASTER_SEED = 42
master_rng = default_rng(MASTER_SEED)
mc_seeds = master_rng.integers(1, 2**31 - 1, size=R)

# -----------------------------
# DGP
# -----------------------------
def generate_data(G, NG, beta_0=0, beta_1=1, rng=None):
    if rng is None:
        rng = default_rng()
    zg = rng.normal(size=G)        # componente comum em x
    eps_g = rng.normal(size=G)     # componente comum no erro

    data_list = []
    for g in range(G):
        zig   = rng.normal(size=NG)    # idiossincrático x
        eps_i = rng.normal(size=NG)    # idiossincrático erro

        xig = zg[g] + zig
        uig = eps_g[g] + eps_i
        yig = beta_0 + beta_1 * xig + uig

        data_list.append(pd.DataFrame({
            "y": yig, "x": xig, "cluster": g + 1
        }))
    return pd.concat(data_list, ignore_index=True)

# -----------------------------
# Estimadores
# -----------------------------
def beta1_point_estimate(df):
    X = sm.add_constant(df["x"].to_numpy())
    y = df["y"].to_numpy()
    ols = sm.OLS(y, X).fit()
    return float(ols.params[1])

def pairs_cluster_bootstrap(df, B=399, rng=None):
    if rng is None:
        rng = default_rng()
    clusters = df["cluster"].unique()
    G = len(clusters)
    betas_boot = np.empty(B)
    for b in range(B):
        boot_clusters = rng.choice(clusters, size=G, replace=True)
        boot_df = pd.concat([df[df["cluster"] == g] for g in boot_clusters], ignore_index=True)
        betas_boot[b] = beta1_point_estimate(boot_df)
    return betas_boot

def jackknife_by_cluster(df):
    clusters = df["cluster"].unique()
    betas_jk = []
    for g in clusters:
        df_jk = df[df["cluster"] != g]
        betas_jk.append(beta1_point_estimate(df_jk))
    return np.asarray(betas_jk)

def bca_interval(beta_hat, betas_boot, betas_jk, alpha=0.05):
    # z0 (bias-correction)
    prop = np.clip(np.mean(betas_boot < beta_hat), 1e-12, 1 - 1e-12)
    z0 = norm.ppf(prop)

    # a (acceleration) via jackknife
    beta_bar = np.mean(betas_jk)
    num = np.sum((beta_bar - betas_jk)**3)
    den = 6.0 * (np.sum((beta_bar - betas_jk)**2) ** 1.5)
    a = num/den if den > 0 else 0.0

    # quantis ajustados
    z_low, z_high = norm.ppf(alpha/2), norm.ppf(1 - alpha/2)
    adj_low  = norm.cdf(z0 + (z0 + z_low)  / (1 - a * (z0 + z_low)))
    adj_high = norm.cdf(z0 + (z0 + z_high) / (1 - a * (z0 + z_high)))

    q_low  = np.quantile(betas_boot, adj_low)
    q_high = np.quantile(betas_boot, adj_high)
    return float(q_low), float(q_high)

def pairs_cluster_bootstrap_bca_test(df, beta_true, B=399, alpha=0.05, rng=None):
    if rng is None:
        rng = default_rng()
    beta_hat = beta1_point_estimate(df)
    betas_boot = pairs_cluster_bootstrap(df, B=B, rng=rng)
    betas_jk = jackknife_by_cluster(df)
    ci_low, ci_high = bca_interval(beta_hat, betas_boot, betas_jk, alpha=alpha)
    reject = not (ci_low <= beta_true <= ci_high)
    return reject, (ci_low, ci_high), beta_hat

# -----------------------------
# 1 réplica Monte Carlo (para paralelização)
# -----------------------------
def mc_one_rep(seed, G, NG, beta_true, B, alpha):
    rng = default_rng(seed)
    df = generate_data(G, NG, beta_0=0, beta_1=beta_true, rng=rng)
    rej, _, _ = pairs_cluster_bootstrap_bca_test(df, beta_true=beta_true, B=B, alpha=alpha, rng=rng)
    return int(rej)

# -----------------------------
# Rodar Monte Carlo em paralelo
# -----------------------------
def run_monte_carlo_pairs_bca_parallel(R, G, NG, beta_true=1.0, B=399, alpha=0.05, n_jobs=-1, verbose=0):
    results = Parallel(n_jobs=n_jobs, verbose=verbose)(
        delayed(mc_one_rep)(int(mc_seeds[r]), G, NG, beta_true, B, alpha) for r in range(R)
    )
    results = np.asarray(results)
    rejection_rate = float(results.mean())
    sd_rejection = float(np.sqrt(rejection_rate * (1 - rejection_rate) / R))
    return rejection_rate, sd_rejection

# -----------------------------
# Executar
# -----------------------------
rejection_rate, sd_rej = run_monte_carlo_pairs_bca_parallel(
    R=R, G=G, NG=NG, beta_true=beta_1, B=B, alpha=alpha, n_jobs=-1, verbose=0
)

print(f"Rejection rate (Pairs cluster bootstrap-BCA, B={B}): {rejection_rate:.4f}")
print(f"Desvio-padrão da rejection rate: {sd_rej:.4f}")

# Exemplo único (opcional): IC BCA e beta_hat
rng_demo = default_rng(123)
df_demo = generate_data(G, NG, beta_0=0, beta_1=beta_1, rng=rng_demo)
rej_demo, (lo, hi), beta_hat_demo = pairs_cluster_bootstrap_bca_test(df_demo, beta_true=beta_1, B=B, alpha=alpha, rng=rng_demo)
print(f"Exemplo (uma amostra): beta_hat={beta_hat_demo:.4f}, IC_BCA({int((1-alpha)*100)}%)=({lo:.4f}, {hi:.4f}), rejeita H0? {rej_demo}")
